from llama_cpp import Llama
from tqdm import tqdm
import os
import json
import re

# LLM ì§ˆì˜ ì²˜ë¦¬ í•¨ìˆ˜
def process_ask_to_llm(text: str) -> str:

    results = process_pipeline(text)
    print("\nâœ… ìµœì¢… ê²€ì¦ëœ JSON ê²°ê³¼:")
    for item in results:
        print(json.dumps(item, ensure_ascii=False, indent=2))
    return results


# ëª¨ë¸ ê²½ë¡œ ì„¤ì • (WSL ê¸°ì¤€)
model_path = "/mnt/d/models/nous/Nous-Hermes-2-Mistral-7B-DPO.Q4_K_M.gguf"

# ëª¨ë¸ ê²½ë¡œ ìœ íš¨ì„± ê²€ì‚¬
if not os.path.exists(model_path):
    raise FileNotFoundError(f"ëª¨ë¸ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}")

# ëª¨ë¸ ì´ˆê¸°í™”
llm = Llama(
    model_path=model_path,
    n_ctx=2048,
    n_threads=6,
    use_mlock=False
)

# í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í•  í•¨ìˆ˜
def split_text_into_chunks(text: str, max_chars: int = 1000):
    return [text[i:i + max_chars] for i in range(0, len(text), max_chars)]


# ë‹¨ê³„ 1: ì˜¤íƒˆì ë° ëª…ì¹­ ì •ê·œí™”
def correct_typos(text: str) -> str:
    chunks = split_text_into_chunks(text, max_chars=800)
    corrected_chunks = []
    for chunk in chunks:
        prompt = (
            "ë‹¤ìŒ í…ìŠ¤íŠ¸ëŠ” ìœ„ìŠ¤í‚¤ ê´€ë ¨ ì •ë³´ì•¼. ì˜¤íƒˆìë‚˜ ì˜ëª»ëœ í‘œê¸° (ìœ„ìŠ¤í‚¤ ì´ë¦„ì´ë‚˜ ë¸Œëœë“œ)ë¥¼ "
            "ì •í™•í•˜ê²Œ ìˆ˜ì •í•´ì¤˜. ê²°ê³¼ëŠ” ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œ ì¶œë ¥í•´ì¤˜.\n\n"
            f"```{chunk}```"
        )
        result = llm(prompt, max_tokens=512, stop=["```"])
        corrected_chunks.append(result["choices"][0]["text"].strip())
    return "\n".join(corrected_chunks)


# ë‹¨ê³„ 2: JSON ì¶”ì¶œ
def extract_whisky_json(text: str) -> str:
    chunks = split_text_into_chunks(text, max_chars=800)
    json_results = []
    for chunk in chunks:
        prompt = (
            "ë‹¤ìŒì€ ì •ì œëœ ìœ„ìŠ¤í‚¤ ì •ë³´ì•¼. ì—¬ê¸°ì—ì„œ ìœ„ìŠ¤í‚¤ ì´ë¦„_ì—°ë„í¬í•¨(name_age), ìš©ëŸ‰(volume_ml), "
            "ê°€ê²©(price_krw), ë‚ ì§œ(date)ë¥¼ í¬í•¨í•œ JSON ê°ì²´ë“¤ì„ ì¶”ì¶œí•´ì¤˜. "
            "ë³µìˆ˜ í•­ëª©ì´ë¼ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶œë ¥í•´ì¤˜:\n\n"
            f"```{chunk}```"
        )
        result = llm(prompt, max_tokens=1024, stop=["```"])
        json_results.append(result["choices"][0]["text"].strip())
    return "\n".join(json_results)



# ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
def process_pipeline(raw_text) :
    # 1ë‹¨ê³„: ì˜¤íƒˆì êµì •
    print("ğŸ“˜ 1ë‹¨ê³„: ì˜¤íƒˆì ë° ëª…ì¹­ ì •ê·œí™” ì¤‘...")
    corrected = correct_typos(raw_text)

    # 2ë‹¨ê³„: JSON ì¶”ì¶œ
    print("ğŸ“— 2ë‹¨ê³„: JSON ì¶”ì¶œ ì¤‘...")
    json_text = extract_whisky_json(corrected)


    return json_text

